{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "## Install libraries",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "import os\nimport sys\nos.system(f\"{sys.executable} -m pip install --quiet openpyxl\")\nos.system(f\"{sys.executable} -m pip install --quiet unidecode\")\nos.system(f\"{sys.executable} -m pip install --quiet redshift_connector\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "0\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Import libraries",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "from awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom awsglue.context import GlueContext\nfrom pyspark.context import SparkContext\nfrom awsglue.job import Job\nimport pandas as pd\nimport redshift_connector\nimport psycopg2\nfrom unidecode import unidecode\nimport warnings\nwarnings.filterwarnings('ignore')",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "sc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Initial definitions:",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "### Variable types:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "dict_types = {\n            'AÑOMES':int,\n            'NATURALEZA':str,\n            'CODIGO_CARGUE':int,\n            'CODIGO_DESCARGUE': int,\n            'HORAS_VIAJE':float,\n            'HORAS_ESPERA_CARGUE':float,\n            'HORAS_CARGUE':float,\n            'HORAS_ESPERA_DESCARGUE':float,\n            'HORAS_DESCARGUE':float,\n            'CONFIGURACION':str\n            }\n\nls_read_values = list(dict_types.keys())",
			"metadata": {
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Dimensions and RedShift tables dictionary:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# This dictionary represent all those columns that are necessary to build the dimension tables of the model.\n# The keys represent the code names of the file, the values are a list in which the first element is the dimesion table related to\n# that code and the third one represents the idenfitier column name in the dimension table.\n\ndict_dimensions = {\n                'CONFIGURACION':['DIM_CONFIGURACIONES_VEHICULO','ID_CONFIGURACION_VEHICULO'],\n                'CODIGO_CARGUE':['DIM_MUNICIPIOS','ID_MUNICIPIO_ORIGEN'],\n                'CODIGO_DESCARGUE':['DIM_MUNICIPIOS','ID_MUNICIPIO_DESTINO'],\n                'NATURALEZA':['DIM_NATURALEZAS_CARGA','ID_NATURALEZA_CARGA']\n                }",
			"metadata": {
				"trusted": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Fact table columns:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "dict_fact = {\n            'AÑOMES':['AÑOMES','ANO_MES'],\n            'CONFIGURACION':['ID_CONFIGURACION_VEHICULO','ID_CONFIGURACION_VEHICULO'],\n            'NATURALEZA':['ID_NATURALEZA_CARGA','ID_NATURALEZA_CARGA'],\n            'CODIGO_CARGUE':['ID_MUNICIPIO_ORIGEN','ID_MUNICIPIO_ORIGEN'],\n            'CODIGO_DESCARGUE':['ID_MUNICIPIO_DESTINO','ID_MUNICIPIO_DESTINO'],\n            'HORAS_VIAJE':['HORAS_VIAJE','PROMEDIO_HORAS_VIAJE'],\n            'HORAS_ESPERA_CARGUE':['HORAS_ESPERA_CARGUE','PROMEDIO_HORAS_ESPERA_CARGUE'],\n            'HORAS_CARGUE':['HORAS_CARGUE','PROMEDIO_HORAS_CARGUE'],\n            'HORAS_ESPERA_DESCARGUE':['HORAS_ESPERA_DESCARGUE','PROMEDIO_HORAS_ESPERA_DESCARGUE'],\n            'HORAS_DESCARGUE':['HORAS_DESCARGUE','PROMEDIO_HORAS_DESCARGUE']\n            }\n\nls_fact_keys = list(dict_fact.keys())\nls_fact_values = list(dict_fact.values())\nls_order_values = [x[0] for x in ls_fact_values]\nls_redshift_values = [x[-1] for x in ls_fact_values]\ndict_redshift = {k: v[-1] for k, v in dict_fact.items()}",
			"metadata": {
				"trusted": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Redshift connection:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "conn = psycopg2.connect(\n            host = 'redshift-cluster-2.cg5i3fotr9gy.sa-east-1.redshift.amazonaws.com', \n            database = 'dev', \n            port = 5439,\n            user = 'admin', \n            password = 'Awscente1803*.*'\n        )\n\ncursor = conn.cursor()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Retrive parameters from Lambda function:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "args = getResolvedOptions(sys.argv, ['bucket','object_key'])\nbucket = args['bucket']\nobject_key = args['object_key']\n\n# bucket = 'rndc-raw'\n# object_key = 'tiempos_logisticos/RemesasRNDC_202207.txt'",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "## Read the dataset",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df = pd.read_csv(f\"s3://{bucket}/{object_key}\",dtype=dict_types, delimiter = '|', usecols=ls_read_values,encoding='latin-1')",
			"metadata": {
				"trusted": true
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Transformations",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df.drop_duplicates(inplace=True)\n\ndf = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)\ndf = df.applymap(lambda x: unidecode(x) if isinstance(x, str) else x)\ndf = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n\ndf['CODIGO_CARGUE'] = df['CODIGO_CARGUE'].astype(str)\ndf['CODIGO_DESCARGUE'] = df['CODIGO_DESCARGUE'].astype(str)\n\ndf_grouped = df.groupby(by=['AÑOMES','NATURALEZA','CODIGO_CARGUE','CODIGO_DESCARGUE','CONFIGURACION'],as_index=False).mean()\nprint(f\"file: {object_key.split('/')[-1]} | status: refined\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "file: RemesasRNDC_202207.txt | status: refined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Fact table:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_fact = df_grouped[ls_fact_keys]\n\nfor key in dict_dimensions:\n    # Retrieve data from Redshift\n    table_name = dict_dimensions[key][0]\n    id_name = dict_dimensions[key][-1]\n    if key != 'NATURALEZA':\n        query = f'SELECT id AS {id_name}, codigo FROM {table_name}'\n    else:\n        query = f'SELECT id AS {id_name}, naturaleza_carga AS codigo FROM {table_name}'\n    cursor.execute(query)\n    rows = cursor.fetchall()\n    column_names = [desc[0].upper() for desc in cursor.description]\n    df_dimension_redshift = pd.DataFrame(rows, columns=column_names)\n    \n    # Change cod column to its corresponding id\n    df_fact = pd.merge(df_fact,df_dimension_redshift,left_on = key,right_on = 'CODIGO',how = 'left')\n    df_fact.drop([key,'CODIGO'], axis=1, inplace=True)\n\n# Order de columns to save into Redshift\ndf_fact = df_fact[ls_order_values].copy()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "dataset = list(zip(df_fact['ID_MUNICIPIO_DESTINO'], df_fact['ID_MUNICIPIO_ORIGEN'], df_fact['ID_NATURALEZA_CARGA'], df_fact['ID_CONFIGURACION_VEHICULO'], df_fact['AÑOMES'], df_fact['HORAS_DESCARGUE'], df_fact['HORAS_VIAJE'], df_fact['HORAS_ESPERA_DESCARGUE'], df_fact['HORAS_CARGUE'], df_fact['HORAS_ESPERA_CARGUE']))\n\n#consulta = \"DELETE FROM tabla WHERE idnpais = %s AND añomes = %s AND semana = %s AND canal = %s;\"\n#cursor.execute(consulta, (idnpais, aniomes, semana, canal))\n\nconsulta = \"INSERT INTO tiempos_logisticos (id_municipio_destino, id_municipio_origen, id_naturaleza_carga, id_configuracion_vehiculo, ano_mes, promedio_horas_descargue, promedio_horas_espera_descargue, promedio_horas_cargue, promedio_horas_espera_cargue, promedio_horas_viaje) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\ncursor.executemany(consulta, (dataset))\nconn.commit()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "Index(['AÑOMES', 'ID_CONFIGURACION_VEHICULO', 'ID_NATURALEZA_CARGA',\n       'ID_MUNICIPIO_ORIGEN', 'ID_MUNICIPIO_DESTINO', 'HORAS_VIAJE',\n       'HORAS_ESPERA_CARGUE', 'HORAS_CARGUE', 'HORAS_ESPERA_DESCARGUE',\n       'HORAS_DESCARGUE'],\n      dtype='object')\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "cursor.close()\nconn.close()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 86,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}