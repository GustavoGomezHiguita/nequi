{
	"metadata": {
		"toc-autonumbering": true,
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# RNDC ETL job",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "## Install libraries",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "import os\nimport sys\nos.system(f\"{sys.executable} -m pip install --quiet openpyxl\")\nos.system(f\"{sys.executable} -m pip install --quiet unidecode\")\nos.system(f\"{sys.executable} -m pip install --quiet redshift_connector\")\n#os.system(f\"{sys.executable} -m pip install --quiet awswrangler\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.3 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::689317089373:role/AWSGlueServiceRole\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 2986ac50-f78a-499d-9cf2-53e46391154f\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.3\n--enable-glue-datacatalog true\nWaiting for session 2986ac50-f78a-499d-9cf2-53e46391154f to get into ready status...\nSession 2986ac50-f78a-499d-9cf2-53e46391154f has been created.\n0\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Import libraries",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "from awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom awsglue.context import GlueContext\nfrom pyspark.context import SparkContext\nfrom awsglue.job import Job\nimport pandas as pd\n# import boto3\n# import awswrangler as wr\nimport redshift_connector\nfrom unidecode import unidecode\nimport warnings\nwarnings.filterwarnings('ignore')",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "sc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Initial definitions:",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "### Variable types:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "dict_types = {'MES': int,\n            'COD_CONFIG_VEHICULO': str,\n            'CONFIG_VEHICULO': str,\n            'CODOPERACIONTRANSPORTE': str,\n            'OPERACIONTRANSPORTE':str,\n            'CODTIPOCONTENEDOR': str,\n            'TIPOCONTENEDOR':str,\n            'CODMUNICIPIOORIGEN': int,\n            'MUNICIPIOORIGEN': str,\n            'CODMUNICIPIODESTINO': int,\n            'MUNICIPIODESTINO': str,\n            'CODMERCANCIA': str,\n            'MERCANCIA': str,  \n            'NATURALEZACARGA': str,\n            'VIAJESTOTALES': int,\n            'KILOGRAMOS': float,\n            'GALONES': float,\n            'VIAJESLIQUIDOS': int,\n            'VIAJESVALORCERO': int,\n            'KILOMETROS': float,\n            'VALORESPAGADOS': float,\n            'CODMUNICIPIOINTERMEDIO': int,\n            'MUNICIPIOINTERMEDIO': str,\n            'KILOMETROSREGRESO': float,\n            'KILOGRAMOSREGRESO': float,\n            'GALONESREGRESO': float}",
			"metadata": {
				"trusted": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Dimensions and RedShift tables dictionary:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# This dictionary represent all those columns that are necessary to build the dimension tables of the model.\n# The keys represent the code names of the file, the values are a list in which the first element is the description of the code, the second is the dimesion table related to\n# that code and the third one represents the idenfitier column name in the dimension table.\n\ndict_dimensions = {\n                'COD_CONFIG_VEHICULO':['CONFIG_VEHICULO','DIM_CONFIGURACIONES_VEHICULO','ID_CONFIGURACION_VEHICULO'],\n                'CODOPERACIONTRANSPORTE':['OPERACIONTRANSPORTE','DIM_OPERACIONES_TRANSPORTE','ID_OPERACION_TRANSPORTE'],\n                'CODTIPOCONTENEDOR':['TIPOCONTENEDOR','DIM_TIPOS_CONTENEDOR','ID_TIPO_CONTENEDOR'],\n                'CODMUNICIPIOORIGEN':['MUNICIPIOORIGEN','DIM_MUNICIPIOS','ID_MUNICIPIO_ORIGEN'],\n                'CODMUNICIPIODESTINO':['MUNICIPIODESTINO','DIM_MUNICIPIOS','ID_MUNICIPIO_DESTINO'],\n                'CODMERCANCIA':['MERCANCIA','DIM_MERCANCIAS','ID_MERCANCIA'],\n                'CODMUNICIPIOINTERMEDIO':['MUNICIPIOINTERMEDIO','DIM_MUNICIPIOS','ID_MUNICIPIO_INTERMEDIO'],\n                'NATURALEZACARGA':['NATURALEZACARGA','DIM_NATURALEZAS_CARGA','ID_NATURALEZA_CARGA']\n                }",
			"metadata": {
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Fact table columns:",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "# This dictionary represent all those columns that are necessary to build the fact table of the model.\n# The keys represent the column names that will be necessary to build the fact table, the values are a list in which the first element is the field order that is\n# going to be used and the second one represents the name of the column in the Redshift table.\n\ndict_fact = {\n            'MES':['MES','ANO_MES'],\n            'COD_CONFIG_VEHICULO':['ID_CONFIGURACION_VEHICULO','ID_CONFIGURACION_VEHICULO'],\n            'CODOPERACIONTRANSPORTE':['ID_OPERACION_TRANSPORTE','ID_OPERACION_TRANSPORTE'],\n            'CODTIPOCONTENEDOR':['ID_TIPO_CONTENEDOR','ID_TIPO_CONTENEDOR'],\n            'CODMUNICIPIOORIGEN':['ID_MUNICIPIO_ORIGEN','ID_MUNICIPIO_ORIGEN'],\n            'CODMUNICIPIODESTINO':['ID_MUNICIPIO_DESTINO','ID_MUNICIPIO_DESTINO'],\n            'NATURALEZACARGA':['ID_NATURALEZA_CARGA','ID_NATURALEZA_CARGA'],\n            'CODMERCANCIA':['ID_MERCANCIA','ID_MERCANCIA'],\n            'VIAJESTOTALES':['VIAJESTOTALES','VIAJES_TOTALES'],\n            'KILOGRAMOS':['KILOGRAMOS','KILOGRAMOS'],\n            'GALONES':['GALONES','GALONES'],\n            'VIAJESLIQUIDOS':['VIAJESLIQUIDOS','VIAJES_LIQUIDOS'],\n            'VIAJESVALORCERO':['VIAJESVALORCERO','VIAJES_VALOR_CERO'],\n            'KILOMETROS':['KILOMETROS','KILOMETROS'],\n            'VALORESPAGADOS':['VALORESPAGADOS','VALORES_PAGADOS'],\n            'CODMUNICIPIOINTERMEDIO':['ID_MUNICIPIO_INTERMEDIO','ID_MUNICIPIO_INTERMEDIO'],\n            'KILOMETROSREGRESO':['KILOMETROSREGRESO','KILOMETROS_REGRESO'],\n            'KILOGRAMOSREGRESO':['KILOGRAMOSREGRESO','KILOGRAMOS_REGRESO'],\n            'GALONESREGRESO':['GALONESREGRESO','GALONES_REGRESO']\n            }\n\nls_fact_keys = list(dict_fact.keys())\nls_fact_values = list(dict_fact.values())\nls_order_values = [x[0] for x in ls_fact_values]\nls_redshift_values = [x[-1] for x in ls_fact_values]\ndict_redshift = {k: v[-1] for k, v in dict_fact.items()}",
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Redshift connection:",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "conn = redshift_connector.connect(\n        host='redshift-cluster-2.cg5i3fotr9gy.sa-east-1.redshift.amazonaws.com',\n        database='dev',\n        port=5439,\n        user='admin',\n        password='Awscente1803*.*',\n        timeout=60\n      )\n\ncursor = conn.cursor()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Retrive parameters from Lambda function:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# args = getResolvedOptions(sys.argv, ['bucket','object_key'])\n# bucket = args['bucket']\n# object_key = args['object_key']\n\nbucket = 'rndc-raw'\nobject_key = 'estadisticas/EstadisticasRNDC_202208.xlsx'",
			"metadata": {
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Read the dataset",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "df = pd.read_excel(f\"s3://{bucket}/{object_key}\",dtype=dict_types)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Transformations",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df.drop_duplicates(inplace=True)\ndf = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)\ndf = df.applymap(lambda x: unidecode(x) if isinstance(x, str) else x)\ndf = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\ndf['CODMUNICIPIOORIGEN'] = df['CODMUNICIPIOORIGEN'].astype(str)\ndf['CODMUNICIPIODESTINO'] = df['CODMUNICIPIODESTINO'].astype(str)\ndf['CODMUNICIPIOINTERMEDIO'] = df['CODMUNICIPIOINTERMEDIO'].astype(str)\nprint(f\"file: {object_key.split('/')[-1]} | status: refined\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "file: EstadisticasRNDC_202208.xlsx | status: refined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Dimesions tables:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "for key in dict_dimensions:\n    \n    # Create dataframe with the coluns required to represent the dimension\n    cod_description = dict_dimensions[key][0]\n    if key != 'NATURALEZACARGA':\n        df_dimension = df[[key,cod_description]]\n    else:\n        df_dimension = df[[key]]\n    df_dimension.drop_duplicates(subset=[key],inplace=True)\n    \n    # Retrieve data from Redshift\n    table_name = dict_dimensions[key][1]\n    query = f'SELECT * FROM {table_name}'\n    cursor.execute(query)\n    rows = cursor.fetchall()\n    column_names = [desc[0] for desc in cursor.description]\n    df_dimension_redshift = pd.DataFrame(rows, columns=column_names)\n    \n    # Identify new values for the dimension\n    if key != 'NATURALEZACARGA':\n        df_merged = pd.merge(df_dimension, df_dimension_redshift, how='left', left_on = key, right_on = 'codigo')\n        df_merged = df_merged[pd.isna(df_merged['codigo'])]\n    else:\n        df_merged = pd.merge(df_dimension, df_dimension_redshift, how='left', left_on = key, right_on = 'naturaleza_carga') # esta dimensión no tiene código\n        df_merged = df_merged[pd.isna(df_merged['naturaleza_carga'])]\n        \n    # Delete right columns\n    left_columns = df_dimension.columns\n    right_columns_to_drop = [col for col in df_merged.columns if col not in left_columns]\n    df_merged = df_merged.drop(columns=right_columns_to_drop)\n    \n    #Insert data if there are new records to be inserted\n    if df_merged.empty != True:\n        data = [tuple(row) for row in df_merged.itertuples(index=False)]\n        ls_col = df_dimension.columns.to_list()\n        ls_col_redshift = df_dimension_redshift.columns.to_list()\n        ls_col_redshift.remove('id')\n        col_text = \",\".join(ls_col_redshift)\n        query = f\"INSERT INTO {table_name} ({col_text}) VALUES ({','.join(['%s']*len(ls_col))})\"\n        cursor.executemany(query, data)\n        conn.commit()\n        print(f'table: {table_name} | inserted new row(s): {len(df_merged)}')\n    else:\n        print(f'table: {table_name} | not new values')",
			"metadata": {
				"trusted": true
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_CONFIGURACIONES_VEHICULO | inserted new row(s): 1\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_OPERACIONES_TRANSPORTE | inserted new row(s): 1\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_TIPOS_CONTENEDOR | not new values\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_MUNICIPIOS | inserted new row(s): 87\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_MUNICIPIOS | inserted new row(s): 209\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_MERCANCIAS | inserted new row(s): 137\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_MUNICIPIOS | inserted new row(s): 1\n<redshift_connector.cursor.Cursor object at 0x7f4986d1cd10>\ntable: DIM_NATURALEZAS_CARGA | not new values\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Fact table:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_fact = df[ls_fact_keys]\n\nfor key in dict_dimensions:\n    # Retrieve data from Redshift\n    table_name = dict_dimensions[key][1]\n    id_name = dict_dimensions[key][-1]\n    if key != 'NATURALEZACARGA':\n        query = f'SELECT id AS {id_name}, codigo FROM {table_name}'\n    else:\n        query = f'SELECT id AS {id_name}, naturaleza_carga AS codigo FROM {table_name}'\n    cursor.execute(query)\n    rows = cursor.fetchall()\n    column_names = [desc[0].upper() for desc in cursor.description]\n    df_dimension_redshift = pd.DataFrame(rows, columns=column_names)\n    \n    # Change cod column to its corresponding id\n    df_fact = pd.merge(df_fact,df_dimension_redshift,left_on = key,right_on = 'CODIGO',how = 'left')\n    df_fact.drop([key,'CODIGO'], axis=1, inplace=True)\n\n# Order de columns to save into Redshift\ndf_fact = df_fact[ls_order_values].copy()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 12,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "chunk_size = 1000\nnum_chunks = len(df_fact) // chunk_size + 1\n\nfor i in range(num_chunks):\n    start = i * chunk_size\n    end = (i + 1) * chunk_size\n    chunk = df_fact[start:end]\n\n    # Insert data\n    data = [tuple(row) for row in chunk.itertuples(index=False)]\n    col_text = \",\".join(ls_redshift_values)\n    query = f\"INSERT INTO estadisticas ({col_text}) VALUES ({','.join(['%s']*len(ls_redshift_values))})\"\n    cursor.executemany(query, data)\n    conn.commit()\n    print(f'chunk: {i}/{num_chunks} | table: {table_name} | inserted new row(s): {len(df_fact)}')",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": [
				{
					"name": "stdout",
					"text": "Execution Interrupted. Attempting to cancel the statement (statement_id=17)\nStatement 17 has been cancelled\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "cursor.close()\nconn.close()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}